{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout, BatchNormalization, Activation\n\nfrom keras.preprocessing.image import ImageDataGenerator \n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")","execution_count":57,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"                                     id  has_cactus\n0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n2  000d1e9a533f62e55c289303b072733d.jpg           1\n3  0011485b40695e9138e92d0b3fb55128.jpg           1\n4  0014d7a11e90b62848904c1418fc8cf2.jpg           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>has_cactus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0004be2cfeaba1c0361d39e2b000257b.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000c8a36845c0208e833c79c1bffedd1.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000d1e9a533f62e55c289303b072733d.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0011485b40695e9138e92d0b3fb55128.jpg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0014d7a11e90b62848904c1418fc8cf2.jpg</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"has_cactus\"] = train[\"has_cactus\"].map(lambda x:str(x))\ntrain.shape","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"(17500, 2)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The dataset being relatively small, data augmentation is very important to generalise and learn what a cactus look like. Based on the fact that cactus detection seems like an easy problem and we're dealing with a small amount of data, the batch size is kept small as training will be quick anyway."},{"metadata":{},"cell_type":"markdown","source":"### Image Data Generator"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1, \n                                  horizontal_flip=True, vertical_flip=True)\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=train,\n                                                   directory = \"../input/train/train\",\n                                                   x_col=\"id\", y_col=\"has_cactus\",\n                                                   batch_size=32, shuffle=True,\n                                                   class_mode=\"binary\",\n                                                   target_size=(32, 32),\n                                                   subset=\"training\")","execution_count":60,"outputs":[{"output_type":"stream","text":"Found 15750 images belonging to 2 classes.\nCPU times: user 240 ms, sys: 316 ms, total: 556 ms\nWall time: 2.03 s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nval_generator = train_datagen.flow_from_dataframe(dataframe=train,\n                                                 directory = \"../input/train/train\",\n                                                 x_col=\"id\", y_col=\"has_cactus\",\n                                                 batch_size=32, shuffle=True,\n                                                 class_mode=\"binary\",\n                                                 target_size=(32, 32),\n                                                 subset=\"validation\")","execution_count":61,"outputs":[{"output_type":"stream","text":"Found 1750 images belonging to 2 classes.\nCPU times: user 108 ms, sys: 72 ms, total: 180 ms\nWall time: 179 ms\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (32, 32, 3)\nnum_classes = 2","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), input_shape=input_shape))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\n\nmodel.add(Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.6))\n\nmodel.add(Dense(1))\nmodel.add(Activation('sigmoid'))","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n             optimizer='adam',\n             metrics=['accuracy'])","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Model = model.fit_generator(generator=train_generator,\n                           validation_data=val_generator,\n                           validation_steps=int(train.shape[0]/32),\n                           steps_per_epoch=int(train.shape[0]/32),\n                           epochs=20, verbose=1)","execution_count":65,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n546/546 [==============================] - 39s 71ms/step - loss: 0.1459 - acc: 0.9467 - val_loss: 0.1180 - val_acc: 0.9548\nEpoch 2/20\n546/546 [==============================] - 34s 63ms/step - loss: 0.0729 - acc: 0.9750 - val_loss: 0.1283 - val_acc: 0.9549\nEpoch 3/20\n546/546 [==============================] - 36s 65ms/step - loss: 0.0726 - acc: 0.9762 - val_loss: 0.0766 - val_acc: 0.9765\nEpoch 4/20\n546/546 [==============================] - 34s 63ms/step - loss: 0.0604 - acc: 0.9802 - val_loss: 0.0761 - val_acc: 0.9750\nEpoch 5/20\n546/546 [==============================] - 36s 66ms/step - loss: 0.0413 - acc: 0.9863 - val_loss: 0.0469 - val_acc: 0.9875\nEpoch 6/20\n546/546 [==============================] - 35s 64ms/step - loss: 0.0363 - acc: 0.9895 - val_loss: 0.0828 - val_acc: 0.9717\nEpoch 7/20\n546/546 [==============================] - 34s 62ms/step - loss: 0.0291 - acc: 0.9906 - val_loss: 0.2466 - val_acc: 0.9407\nEpoch 8/20\n546/546 [==============================] - 36s 65ms/step - loss: 0.0382 - acc: 0.9887 - val_loss: 0.0590 - val_acc: 0.9839\nEpoch 9/20\n546/546 [==============================] - 35s 63ms/step - loss: 0.0325 - acc: 0.9901 - val_loss: 0.0832 - val_acc: 0.9727\nEpoch 10/20\n546/546 [==============================] - 35s 64ms/step - loss: 0.0262 - acc: 0.9912 - val_loss: 0.1189 - val_acc: 0.9486\nEpoch 11/20\n546/546 [==============================] - 34s 63ms/step - loss: 0.0243 - acc: 0.9923 - val_loss: 0.0753 - val_acc: 0.9787\nEpoch 12/20\n546/546 [==============================] - 35s 64ms/step - loss: 0.0203 - acc: 0.9940 - val_loss: 0.0797 - val_acc: 0.9722\nEpoch 13/20\n546/546 [==============================] - 34s 62ms/step - loss: 0.0189 - acc: 0.9939 - val_loss: 0.0447 - val_acc: 0.9906\nEpoch 14/20\n546/546 [==============================] - 35s 65ms/step - loss: 0.0182 - acc: 0.9942 - val_loss: 0.0497 - val_acc: 0.9811\nEpoch 15/20\n546/546 [==============================] - 36s 65ms/step - loss: 0.0203 - acc: 0.9938 - val_loss: 0.0300 - val_acc: 0.9930\nEpoch 16/20\n546/546 [==============================] - 34s 62ms/step - loss: 0.0169 - acc: 0.9948 - val_loss: 0.0235 - val_acc: 0.9926\nEpoch 17/20\n546/546 [==============================] - 35s 64ms/step - loss: 0.0143 - acc: 0.9961 - val_loss: 0.0248 - val_acc: 0.9936\nEpoch 18/20\n546/546 [==============================] - 34s 62ms/step - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0226 - val_acc: 0.9916\nEpoch 19/20\n546/546 [==============================] - 34s 63ms/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.0278 - val_acc: 0.9941\nEpoch 20/20\n546/546 [==============================] - 34s 62ms/step - loss: 0.0155 - acc: 0.9959 - val_loss: 0.1129 - val_acc: 0.9773\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir=\"../input/test/test/\"","execution_count":66,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nfrom tqdm import tqdm, tqdm_notebook\n\nX_test = []\nX_image = []\n\nfor image in tqdm_notebook(os.listdir(test_dir)):\n    X_test.append(cv2.imread(test_dir+image))\n    X_image.append(image)\nX_test = np.array(X_test)\nX_test = X_test/255.0","execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(IntProgress(value=0, max=4000), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4813476f86e492fa700deb9c5c11fa3"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"testPredict = model.predict(X_test)","execution_count":68,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.DataFrame(testPredict,columns=['has_cactus'])","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['id'] = ''\ncols=list(submission.columns)\ncols = cols[-1:] + cols[:-1]\nsubmission=submission[cols]\nfor i, img in enumerate(X_image):\n    submission.set_value(i,'id',img)\nprint(submission)","execution_count":70,"outputs":[{"output_type":"stream","text":"                                        id  has_cactus\n0     6a571b6df250e9575fb82f8904c325a1.jpg    1.000000\n1     2edb0bf826248b088d57e22799464c41.jpg    1.000000\n2     ea9422f63363a362ba6f482617006e76.jpg    1.000000\n3     1021509e308bf12f71a01cac2ddca97f.jpg    1.000000\n4     5eacbb413e5cd4e73cb7b1936758abf1.jpg    1.000000\n5     861dccb4950b74108760daae0a1e016b.jpg    1.000000\n6     6472fab8708bcd522836a9f1c6e9aae6.jpg    0.000000\n7     3a77f9113b60c62b7d30c5f41828ab6b.jpg    1.000000\n8     305d9cefe442e30abae64d84ecc8340e.jpg    1.000000\n9     71957d3a60ca371e441fb6ff5ee6379f.jpg    0.921122\n10    cf86a7bd7d483c530ec9bb805f5fd15a.jpg    0.000320\n11    028c67154cbac90ff396f41aebe58656.jpg    1.000000\n12    cb35339d2d9fd1717f06e3e7f89b17a4.jpg    1.000000\n13    da7a0e4e5bbb277efd612bf9e3b507e6.jpg    0.000000\n14    a715480e25a3178372affa70f34612d6.jpg    1.000000\n15    dc36fd4e43f8646c07dd3cc4481c1792.jpg    1.000000\n16    7ffbc679faca1197297ed482d398a32d.jpg    1.000000\n17    8abcc02b98cd50f5ceb9457cc5ea5824.jpg    1.000000\n18    07ee541d41dcafd82e4560cff7f2883e.jpg    1.000000\n19    a5c5cc3cbe5ab99ccc816169a49472ca.jpg    1.000000\n20    f4fde46f863a8c0aaca2663a81d34f75.jpg    1.000000\n21    5384030deeba63dfc7d49d6d402e7114.jpg    1.000000\n22    593bd6bd7318522249e8815511f08182.jpg    1.000000\n23    f8934277fb051e4ef60d4990e466432e.jpg    0.006886\n24    034bcb31a837f4656e7156d916a02bb6.jpg    0.000102\n25    85970aef3f384bc490991ab8e619ee6c.jpg    1.000000\n26    fa797735be687a50719fa13b75b5c491.jpg    1.000000\n27    247c82abf868b1bc0f3636574c457cf3.jpg    0.139438\n28    ea2957d82e8b040c0d2dba7c78c170c8.jpg    1.000000\n29    2268d22d05cf4783fe9f24c5826a69fa.jpg    1.000000\n...                                    ...         ...\n3970  56252603457e38c4b9d539d6a3be380d.jpg    0.999960\n3971  f2467e4a2f594e138103e4e6ac965f74.jpg    1.000000\n3972  55bcc24b0b3d2dfd43c4eda176a03992.jpg    0.000000\n3973  52e2fdd8b1b12b214ec100885ac2e814.jpg    0.000327\n3974  6d01950b0bd923fea3878ae673270a91.jpg    1.000000\n3975  2bde8260bbda9e74d77aa0ff28cf2ab6.jpg    0.995648\n3976  c471e3ce1047ad5869ebe247c2f345b9.jpg    1.000000\n3977  428449aeed0d9317b6421957399bf502.jpg    1.000000\n3978  86516be1c48ebfe3d1c5e2fdfb254b60.jpg    1.000000\n3979  8c1d88657bd4293c0719de7288a01668.jpg    1.000000\n3980  abf677ac1dc7641baee4a21ab3cd6a2d.jpg    0.005564\n3981  e63307c044ad70255a584f449f5eb958.jpg    1.000000\n3982  7b1aa7396e042961d4405028f820b34c.jpg    1.000000\n3983  dce6bd0871a4fae5896e0db9a33a25b3.jpg    0.000982\n3984  810dc3c424295c13f35242b9b49f6c7e.jpg    0.000000\n3985  bde96aabc07264b2ca48d7f23dde6964.jpg    1.000000\n3986  d622d1b58a96159be808d2f72ad0f4d6.jpg    1.000000\n3987  3248c9605b81898ebebca0b0eefc598d.jpg    1.000000\n3988  38c6466e06faa142385f081fcd11134f.jpg    0.000000\n3989  5762bb146887bf525cbfaa013f398adb.jpg    1.000000\n3990  fd93cb95a0bd3167f3c6772c238290b5.jpg    1.000000\n3991  3bdea2774101354d9a7a8f43435a935b.jpg    1.000000\n3992  a0dd7e6f9eca1465bc3912d5e9088d75.jpg    1.000000\n3993  86effcf79f362aa513e0423e20154a7d.jpg    1.000000\n3994  f09209bbc65b8e9c62bdd8f8aab1020c.jpg    1.000000\n3995  e51d5192a5d7d8e0c9a74aa63bf9f33c.jpg    1.000000\n3996  26668321e22999cb53881af206fde950.jpg    1.000000\n3997  58daf92566af8fb04aaf2d5db4b89f5b.jpg    1.000000\n3998  ab67757aa438e861f697c90421d473d9.jpg    1.000000\n3999  6c93c717710ec3899ec8afab5e8e8dd9.jpg    1.000000\n\n[4000 rows x 2 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":71,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_dir=r\"../input/train/train/\"\n#test_dir=\"../input/test/test/\"\n#test_datagen = ImageDataGenerator(rescale=1./255)\n\n#test_generator = test_datagen.flow_from_directory(directory = test_dir,\n                                       #          target_size=(32, 32),\n                                       #         batch_size=1,\n                                        #         class_mode='binary',\n                                        #         shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Pred = model.fit_generator(test_generator, steps_per_epoch = len(test_generator.filenames), verbose=1)\n#PredBinary = [0 if value<0.50 else 1 for value in Pred]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}